
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Databricks Updates</title>
        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; padding: 20px; color: #37352f; }
            .article { margin-bottom: 30px; padding: 20px; border-left: 4px solid #0070f3; background-color: #f7f7f5; border-radius: 4px; }
            .article-title { font-size: 1.5em; font-weight: 600; margin-bottom: 5px; }
            .translated-label { font-size: 0.8em; color: #999; font-style: italic; margin-top: 10px; }
            .date { font-size: 0.9em; color: #666; margin-bottom: 15px; }
            .content { margin-top: 10px; }
            .original-text, .translated-text { margin-bottom: 10px; }
            .original-text { font-style: normal; }
            .translated-text { font-weight: 400; color: #0070f3; }
            a { text-decoration: none; color: #0070f3; }
            a:hover { text-decoration: underline; }
        </style>
    </head>
    <body>
        <h1>Databricks Docs Updates</h1>
    
        <div class="article">
            <a href="https://docs.databricks.com/aws/en/release-notes/product/2026/january#databricks-runtime-maintenance-updates-0127" target="_blank">
                <div class="article-title">Databricks Runtime maintenance updates (01/27)</div>
            </a>
            <div class="translated-label">&gt; データブリックスランタイムのメンテナンスアップデート (01/27)</div>
            <div class="date">January 27, 2026</div>
            <div class="content">
                <div class="original-text"><p>New maintenance updates are available for supported Databricks Runtime versions. These updates include bug fixes, security patches, and performance improvements. For details, see:</p>
<ul>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#180">Databricks Runtime 18.0</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#173">Databricks Runtime 17.3 LTS</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#172">Databricks Runtime 17.2</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#171">Databricks Runtime 17.1</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#164">Databricks Runtime 16.4 LTS</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#154">Databricks Runtime 15.4 LTS</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#143">Databricks Runtime 14.3 LTS</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#133">Databricks Runtime 13.3 LTS</a></li>
<li><a href="https://docs.databricks.com/aws/en/release-notes/runtime/maintenance-updates#122">Databricks Runtime 12.2 LTS</a></li>
</ul></div>
                <div class="translated-label">&gt; サポートされている Databricks Runtime のバージョンのための新しい保守アップデートが利用可能です。これらのアップデートには、バグ修正、セキュリティパッチ、パフォーマンス改善が含まれています。詳細は以下をご覧ください:

- Databricks Runtime 18.0
- Databricks Runtime 17.3 LTS
- Databricks Runtime 17.2
- Databricks Runtime 17.1
- Databricks Runtime 16.4 LTS
- Databricks Runtime 15.4 LTS
- Databricks Runtime 14.3 LTS
- Databricks Runtime 13.3 LTS
- Databricks Runtime 12.2 LTS</div>
            </div>
        </div>
        
        <div class="article">
            <a href="https://docs.databricks.com/aws/en/release-notes/product/2026/january#agent-bricks-knowledge-assistant-is-now-available-in-more-regions" target="_blank">
                <div class="article-title">Agent Bricks: Knowledge Assistant is now available in more regions</div>
            </a>
            <div class="translated-label">&gt; エージェント ブリックス:ナレッジアシスタントが今、より多くの地域で利用可能になりました。</div>
            <div class="date">January 27, 2026</div>
            <div class="content">
                <div class="original-text"><p>Agent Bricks: Knowledge Assistant is now available in the following AWS regions: <code>us-east-2</code>, <code>ca-central-1</code>, <code>eu-central-1</code>, <code>eu-west-1</code>, <code>ap-southeast-1</code> (requires <a href="https://docs.databricks.com/aws/en/resources/databricks-geos#cross-geo-processing">cross-geo processing</a>), and <code>ap-southeast-2</code> (requires <a href="https://docs.databricks.com/aws/en/resources/databricks-geos#cross-geo-processing">cross-geo processing</a>).</p>
<p>Users in these regions can now use Agent Bricks: Knowledge Assistant to create a production-grade AI agent that can answer questions about their documents and provide high-quality responses with citations.</p>
<p>See <a href="https://docs.databricks.com/aws/en/generative-ai/agent-bricks/knowledge-assistant">Use Agent Bricks: Knowledge Assistant to create a high-quality chatbot over your documents</a>.</p></div>
                <div class="translated-label">&gt; <p>エージェント ブリックス: ナレッジ アシスタントは、次の AWS リージョンで利用可能になりました。<code>us-east-2</code>、<code>ca-central-1</code>、<code>eu-central-1</code>、<code>eu-west-1</code>、<code>ap-southeast-1</code> (クロスジオ プロセッシングが必要)、および <code>ap-southeast-2</code> (クロスジオ プロセッシングが必要)。</p>
<p>これらのリージョンのユーザーは、エージェント ブリックス: ナレッジ アシスタントを使用して、ドキュメントに関する質問に答え、引用を含む高品質な回答を提供する、運用グレードの AI エージェントを作成できるようになりました。</p>
<p><a href="https://docs.databricks.com/aws/en/generative-ai/agent-bricks/knowledge-assistant">ドキュメントでの高品質なチャットボットを作成するためにエージェント ブリックス: ナレッジ アシスタントを使う</a>をご覧ください。</p></div>
            </div>
        </div>
        
        <div class="article">
            <a href="https://docs.databricks.com/aws/en/release-notes/product/2026/january#store-and-query-mlflow-traces-in-unity-catalog-beta" target="_blank">
                <div class="article-title">Store and query MLflow traces in Unity Catalog (Beta)</div>
            </a>
            <div class="translated-label">&gt; Unity Catalog (ベータ版)でMLflowトレースを格納およびクエリする</div>
            <div class="date">January 26, 2026</div>
            <div class="content">
                <div class="original-text"><p>You can now store MLflow traces in Unity Catalog tables using OpenTelemetry format and query them using Databricks SQL. This provides several benefits:</p>
<ul>
<li>Store unlimited traces in Delta tables for long-term retention and analysis</li>
<li>Query trace data directly using SQL through a Databricks SQL warehouse</li>
<li>Manage access control through Unity Catalog schema and table permissions</li>
<li>Ensure compatibility with other OpenTelemetry clients and tools</li>
</ul>
<p>See <a href="https://docs.databricks.com/aws/en/mlflow3/genai/tracing/trace-unity-catalog">Store MLflow traces in Unity Catalog</a> and <a href="https://docs.databricks.com/aws/en/mlflow3/genai/tracing/observe-with-traces/query-dbsql">Query MLflow traces using MLflow Databricks SQL</a>.</p></div>
                <div class="translated-label">&gt; <p>OpenTelemetryフォーマットを使用してUnity CatalogテーブルにMLflowトレースを保存し、Databricks SQLを使ってクエリできるようになりました。これにより以下の利点があります:</p>
<ul>
<li>Delta表に無制限のトレースを保存して長期的に保管・分析できる</li>
<li>Databricks SQLウェアハウスからSQL直接クエリできる</li>
<li>Unity Catalogのスキーマとテーブルの権限でアクセス制御を管理できる</li>
<li>他のOpenTelemetryクライアントやツールとの互換性を確保できる</li>
</ul>
<p><a href="https://docs.databricks.com/aws/en/mlflow3/genai/tracing/trace-unity-catalog">Unity CatalogにMLflowトレースを保存する</a>と<a href="https://docs.databricks.com/aws/en/mlflow3/genai/tracing/observe-with-traces/query-dbsql">MLflow Databricks SQLでMLflowトレースをクエリする</a>をご覧ください。</p></div>
            </div>
        </div>
        
        <div class="article">
            <a href="https://docs.databricks.com/aws/en/release-notes/whats-coming#regional-model-hosting-for-genie-in-japan-and-korea" target="_blank">
                <div class="article-title">Regional model hosting for Genie in Japan and Korea</div>
            </a>
            <div class="translated-label">&gt; 地域モデルホスティングforGenie in Japan and Korea</div>
            <div class="date">January 23, 2026</div>
            <div class="content">
                <div class="original-text"><p>Beginning January 31, 2026, for workspaces in <code>ap-northeast-1</code> (Tokyo) and <code>ap-northeast-2</code> (Seoul) regions, <a href="https://docs.databricks.com/aws/en/genie">Genie</a> will use models hosted in the same region. Users in these regions will no longer require <a href="https://docs.databricks.com/aws/en/resources/databricks-geos#cross-geo-processing">cross-Geo processing</a> to use Genie.</p>
<p>See <a href="https://docs.databricks.com/aws/en/resources/designated-services#ds-availability">Availability of Designated Services in each Geo</a> for more information on which features require cross-geo processing.</p></div>
                <div class="translated-label">&gt; 2026年1月31日から、ap-northeast-1(東京)およびap-northeast-2(ソウル)リージョンのワークスペースでは、Genieが同じリージョンでホストされているモデルを使用します。これらのリージョンのユーザーは、Genieを使用するためにクロスジオ処理を必要としなくなります。

クロスジオ処理を必要とする機能については、「Availability of Designated Services in each Geo」をご覧ください。</div>
            </div>
        </div>
        
        <div class="article">
            <a href="https://docs.databricks.com/aws/en/release-notes/product/2026/january#google-drive-connector-beta" target="_blank">
                <div class="article-title">Google Drive connector (Beta)</div>
            </a>
            <div class="translated-label">&gt; Googleドライブコネクター（ベータ）</div>
            <div class="date">January 23, 2026</div>
            <div class="content">
                <div class="original-text"><p>The standard Google Drive connector in Lakeflow Connect allows you ingest Google Drive files into Databricks. You can use <code>read_files</code>, <code>spark.read</code>, <code>COPY INTO</code>, and Auto Loader to create Spark DataFrames, materialized views, and streaming tables, enabling you to build custom pipelines for common file ingestion use cases. See <a href="https://docs.databricks.com/aws/en/ingestion/google-drive">Ingest Google Drive files into Databricks</a>.</p></div>
                <div class="translated-label">&gt; Lakeflowtビジネス用コネクターのGoogle Driveコネクターを使うと、Google Driveのファイルをデータブリックスにインジェストできます。<code>read_files</code>、<code>spark.read</code>、<code>COPY INTO</code>、Auto Loaderを使って、Sparkデータフレーム、物化ビュー、ストリーミングテーブルを作成し、一般的なファイルインジェストのユースケースに合わせてカスタムパイプラインを構築できます。<a href="https://docs.databricks.com/aws/en/ingestion/google-drive">Google Driveファイルをデータブリックスにインジェストする</a>をご覧ください。</div>
            </div>
        </div>
        
    </body>
    </html>
    